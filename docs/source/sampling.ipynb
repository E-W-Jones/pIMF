{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf09048a",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "With pIMF it is possible to draw stochastic samples from the imf.\n",
    "\n",
    "_This tutorial notebook can be downloaded and ran on your own system._\n",
    "\n",
    "## Motivation\n",
    "Why would you even want to draw individual stars from the IMF?\n",
    "\n",
    "Scientifically, this is thought to be important when dealing with clusters below $\\sim 10^4\\:\\mathrm{M}_\\odot$. I won't try to list all codes and papers that are used for fear of omission. But a good starting point might be [the third SLUG (Stochastically Lighting Up Galaxies) paper](https://ui.adsabs.harvard.edu/abs/2015MNRAS.452.1447K/abstract). This is because at a certain total mass, the probability of forming a massive star dips below 0.\n",
    "\n",
    "We can roughly arrive at this critical mass as follows:\n",
    "\n",
    "Integrating the IMF from $M_\\star$ to $M_\\textrm{max}$ gives us the probability of forming a star of _at least_ mass $M_\\star$. Setting this to 1 means we are guaranteed to form a star of this mass or greater.\n",
    "\\begin{equation}\n",
    "    \\int_{M_\\star}^{M_\\textrm{max}}\\xi(M)\\mathrm{d}M = 1.\n",
    "\\end{equation}\n",
    "We can set the normalisation of the IMF by noting the total mass is given by\n",
    "\\begin{equation}\n",
    "    \\int_{M_\\textrm{min}}^{M_\\textrm{max}}M\\xi(M)\\mathrm{d}M = M_\\textrm{total}.\n",
    "\\end{equation}\n",
    "\n",
    "One can calculate the expected maximum mass observed given a total mass or a total mass given an expected maximum mass. In either case, we find that for a [Salpeter (1955)](./functional_forms/salpeter.md) with a minimum (maximum) mass $0.1 (100)\\:\\mathrm{M}_\\odot$:\n",
    "* to form one star $90\\:\\mathrm{M}_\\odot$ or greater the total mass must be $2.6\\times 10^4\\:\\mathrm{M}_\\odot$.\n",
    "* If we form $5\\times10^4\\:\\mathrm{M}_\\odot$ of stars then we will form one star of at least $95\\:\\mathrm{M}_\\odot$.\n",
    "\n",
    "These are the limits of what we can consider well-sampled, as otherwise we are accounting for a massive star which might not be formed when we average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c7475c",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "In the doctring for `draw_samples` it says that the imf instance we pass needs to include an `inverse_cdf` method. This should be a big hint as to how we sample the IMF.\n",
    "\n",
    "We use inverse CDF sampling (also called [inverse transform sampling](https://en.wikipedia.org/wiki/Inverse_transform_sampling)), which works by generating uniformly random numbers, and plugging them into the inverse of the cumulative distribution function (CDF), also known as the [quantile function](https://en.wikipedia.org/wiki/Quantile_function).\n",
    "\n",
    "This means any IMF we want to sample needs to have an `inverse_cdf` method calculated. Luckily we have already calculated CDFs of all our functions in the `integrate` function, but need to make a change, $\\xi_0 \\rightarrow \\xi_0 / N$, to make our representation generally the same as a PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5a439a",
   "metadata": {},
   "source": [
    "## Generating Samples\n",
    "Below we'll cover how to generate samples with a [fixed number of stars](#a-fixed-number-of-stars), and a [fixed mass in stars](#a-fixed-mass-of-stars).\n",
    "### A fixed number of stars\n",
    "To generate a fixed number of stars, all you need to do is\n",
    "1. generate random numbers however you want, and\n",
    "2. plug them into the inverse_CDF method of your IMF of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4776065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pimf import PowerLawIMF\n",
    "\n",
    "imf = PowerLawIMF(normalisation=\"number\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def summarise_sample(masses, plot=True):\n",
    "    print(f\"Generated {len(masses)} stars with a minimum mass of {min(masses):.2f}, a maximum of {max(masses):.1f}, and a total mass of {sum(masses):.2f}.\")\n",
    "    if not plot:\n",
    "        return\n",
    "    M = np.geomspace(0.1, 100)\n",
    "\n",
    "    # Create a histogram of our sample\n",
    "    plt.hist(\n",
    "        masses,\n",
    "        density=True,  # Density plots it as a PDF\n",
    "        bins=M  # space bins evenly in log-space\n",
    "        )\n",
    "\n",
    "    # Overplot the IMF\n",
    "    plt.plot(\n",
    "        M,\n",
    "        imf(M)\n",
    "    )\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180cd68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With python\n",
    "from random import random\n",
    "\n",
    "N = 10_000\n",
    "masses = []\n",
    "\n",
    "for i in range(N):\n",
    "    uniform_random_number = random()\n",
    "    drawn_mass = imf.inverse_cdf(uniform_random_number)\n",
    "    masses.append(drawn_mass)\n",
    "\n",
    "summarise_sample(masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581adb1",
   "metadata": {},
   "source": [
    "All the included IMFs' `inverse_cdf` methods are vectorised, which means you can leverage `numpy` for faster generation of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "random_numbers = rng.random(size=N)  # Same N as before\n",
    "\n",
    "masses = imf.inverse_cdf(random_numbers)\n",
    "\n",
    "summarise_sample(masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab7296",
   "metadata": {},
   "source": [
    "### A fixed mass of stars\n",
    "In general we don't know a priori how many stars form, instead having a certain amount of mass.\n",
    "\n",
    "At its simplest we can just drop an IMF into `draw_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1def285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pimf import draw_samples\n",
    "\n",
    "masses = draw_samples(imf)\n",
    "summarise_sample(masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9e6dd",
   "metadata": {},
   "source": [
    "By default, we use the mass of the IMF as our target mass, and this IMF has a very small mass.\n",
    "\n",
    "We can change the imf to have a different normalisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b6d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "imf2 = PowerLawIMF(normalisation=\"mass\", normalisation_value=1000)\n",
    "masses = draw_samples(imf2)\n",
    "summarise_sample(masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01339063",
   "metadata": {},
   "source": [
    "Or, we can use the `target_mass` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334788c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "masses = draw_samples(imf, target_mass=1000)\n",
    "summarise_sample(masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a1818",
   "metadata": {},
   "source": [
    "#### How to stop?\n",
    "If you're shooting for a target mass, and generating random masses, you won't end up at your exact target mass. \n",
    "\n",
    "There are three standard methods for how to choose when to stop. They revolve around the final mass you draw. Call $M_\\textrm{total}^{i-1}$ the total mass before drawing the mass $m^i$.\n",
    "1. If $M_\\textrm{total}^{i-1} + m^i > M_\\textrm{target}$, discard $m^i$, so $M_\\textrm{total}^{i-1}$ is the final total mass.\n",
    "2. Even if $M_\\textrm{total}^{i-1} + m^i > M_\\textrm{target}$, keep $m^i$, so $M_\\textrm{total}^{i-1} + m^i$ is the final total mass.\n",
    "3. Keep or discard $m^i$ based on which of $M_\\textrm{total}^{i-1}$ and $M_\\textrm{total}^{i-1}+m^i$ is closer to $M_\\textrm{target}$.\n",
    "\n",
    "You can switch between them using the `stop_method` keyword argument to `draw_samples`, where we call them `below`, `above` and `closest`.\n",
    "\n",
    "We also have 2 **experimental** ways of getting results that are closer to the target mass:\n",
    "1. `smith2021_sampling` is a function that implemements the sampling method described by [Smith (2021)](https://ui.adsabs.harvard.edu/abs/2021MNRAS.502.5417S/abstract). Long story short, when you oversample one IMF you undersample the next, changing the target mass. This should be more accurate in the long run.\n",
    "2. The `rescale` argument of `draw_samples` rescales each mass in the sample by $M_\\mathrm{target}/M_\\mathrm{total}$.\n",
    "\n",
    ":::{note}\n",
    "The absolute difference between the final total mass and target mass will be at most the upper mass limit of the IMF. For the `closest` method it is half of the upper mass limit. This means that your relative error will go down with the total mass formed.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stop_method in [\"above\", \"below\", \"closest\"]:\n",
    "    print(stop_method, end=\": \")\n",
    "    masses = draw_samples(imf, target_mass=1000, stop_method=stop_method)\n",
    "    summarise_sample(masses, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1007fd9b",
   "metadata": {},
   "source": [
    "#### Seeding Random Numbers\n",
    "The random numbers aren't truly random, but depend on some initial condition, called the 'seed'. Specifing this seed means you will always have the same output, which is useful for reproducing results or trying to fix bugs.\n",
    "\n",
    "The `draw_samples` method takes an `rng` keyword argument, which should be an instance of a [`numpy Generator`](https://numpy.org/doc/stable/reference/random/generator.html). This means you can set the seedas below.\n",
    "\n",
    "Technically, you can pass anything to `rng` that has a `uniform` method with a `size` argument. However, I have no idea why you want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "masses = draw_samples(imf, target_mass=1000, rng=rng)\n",
    "\n",
    "# Now, reset the random number generator\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "masses2 = draw_samples(imf, target_mass=1000, rng=rng)\n",
    "\n",
    "print(np.all(masses == masses2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8e4cd6",
   "metadata": {},
   "source": [
    "## Dealing with Samples\n",
    "We have a semi-experimental setup for storing and manipulating samples of masses from the IMF, including being able to save to/read from disk.\n",
    "\n",
    "This is done with the `IMFSample` and `IMFSampleList` classes. The former is a list of masses drawn in one realisation. The latter is a way to do operations on a list of `IMFSample` objects. For example, if you want to study how stochastically sampling the IMF influence the number of ionising photons, you could generate 100 realisations of 1000 solar masses of stars, and compare the total photon output over their lives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420ad62e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pimf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
